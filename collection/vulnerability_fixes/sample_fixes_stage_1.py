import random

import docx
from docx import Document
from docx.enum.dml import MSO_THEME_COLOR_INDEX
import sys
import pandas as pd
from ast import literal_eval

sys.path.append('..')
from vulnerability_fixes.find_fixes import load_update_commits, load_advisory_database, associate_commits_with_vulns  # noqa: E402
from vulnerability_fixes.identify import identify_applicable_vulnerabilities  # noqa: E402
from finder import *  # noqa: E402


# credit: https://stackoverflow.com/a/47666747/14376026
def add_hyperlink(paragraph, text, url):
    # This gets access to the document.xml.rels file and gets a new relation id value
    part = paragraph.part
    r_id = part.relate_to(url, docx.opc.constants.RELATIONSHIP_TYPE.HYPERLINK, is_external=True)

    # Create the w:hyperlink tag and add needed values
    hyperlink = docx.oxml.shared.OxmlElement('w:hyperlink')
    hyperlink.set(docx.oxml.shared.qn('r:id'), r_id, )

    # Create a w:r element and a new w:rPr element
    new_run = docx.oxml.shared.OxmlElement('w:r')
    rPr = docx.oxml.shared.OxmlElement('w:rPr')

    # Join all the xml elements together add add the required text to the w:r element
    new_run.append(rPr)
    new_run.text = text
    hyperlink.append(new_run)

    # Create a new Run object and add the hyperlink into it
    r = paragraph.add_run ()
    r._r.append (hyperlink)

    # A workaround for the lack of a hyperlink style (doesn't go purple after using the link)
    # Delete this if using a template that has the hyperlink style in it
    r.font.color.theme_color = MSO_THEME_COLOR_INDEX.HYPERLINK
    r.font.underline = True

    return hyperlink


def create_title_page(doc):
    doc.add_heading('Labelling: Stage 1', 0)
    document.add_page_break()


def create_page(doc, index, fix_row, database):
    doc.add_heading('Case {}'.format(index), level=1)
    p = doc.add_paragraph('Project: ')
    add_hyperlink(p, fix_row['repository'], 'https://github.com/{}'.format(fix_row['repository']))
    p = doc.add_paragraph('Pull Request: ')
    add_hyperlink(p, fix_row['url'], fix_row['url'])
    p = doc.add_paragraph('Vulnerable Package: ')
    p.add_run(fix_row['package']).bold = True
    doc.add_paragraph('Directories')
    dirs = set()
    for file in row['files']:
        if file.split('/')[-1] in ['package.json', 'package-lock.json', 'yarn.lock', 'npm-shrinkwrap.json']:
            dirs.add(os.path.dirname(file))
    for dir in dirs:
        doc.add_paragraph(dir + '/', style='List Bullet')
    concerned_advisory_records = database[database['ghsa'] == row['ghsa']]
    table = doc.add_table(rows=1, cols=2)
    hdr_cells = table.rows[0].cells
    hdr_cells[0].text = 'Affected'
    hdr_cells[1].text = 'First Patched Release'
    for _, row_a in concerned_advisory_records.iterrows():
        row_cells = table.add_row().cells
        row_cells[0].text = str(row_a['vulnerableVersionRange'])
        row_cells[1].text = str(row_a['firstPatchedVersion'])
    for index_c, commit in enumerate(fix_row['commits']):
        p = doc.add_paragraph('', style='List Bullet')
        add_hyperlink(p, 'Commit {}'.format(index_c), 'https://github.com/{}/commit/{}'.format(fix_row['repository'],
                                                                                           commit))
    case_ar.append(index)
    repository_ar.append(fix_row['repository'])
    number_ar.append(fix_row['number'])
    package_ar.append(fix_row['package'])
    ghsa_ar.append(fix_row['ghsa'])
    commit_fix_ar.append(fix_row['commit_fix'])
    blank_ar.append(None)
    doc.add_page_break()


if __name__ == '__main__':
    document = Document()
    create_title_page(document)
    fixes = pd.read_csv(PATH_VULNERABILITY_FIXES['fixes'], index_col=False)
    fixes_labels = pd.read_csv(PATH_VULNERABILITY_FIXES['fixes_labels'], index_col=False)
    fixes['commits'] = fixes['commits'].apply(literal_eval)
    upd_commits = associate_commits_with_vulns()
    advisory_database = load_advisory_database()
    fixes = fixes.merge(upd_commits, how='inner', on=['url', 'repository', 'state', 'number', 'package'])
    fixes = fixes.merge(fixes_labels, how='inner', on=['repository', 'number', 'package', 'ghsa', 'fixed']).reset_index()
    fixes = fixes[fixes['fixed']]
    simple_fixes = []
    complex_fixes = []
    for index, row in fixes.iterrows():
        if row['commit_fix'] in row['commits']:
            simple_fixes.append(row)
        elif not(row['commit_fix'] in row['commits']) and (row['by'] != 'bot'):
            complex_fixes.append(row)
    random_fixes = random.sample(simple_fixes, 25)
    random_fixes.extend(random.sample(complex_fixes, 25))
    random.shuffle(random_fixes)
    case_ar = []
    repository_ar = []
    number_ar = []
    package_ar = []
    ghsa_ar = []
    commit_fix_ar = []
    blank_ar = []
    for index, row in enumerate(random_fixes):
        create_page(document, index, row, advisory_database)
    document.save(PATH_VULNERABILITY_FIXES['stage_1_second_rater_doc'])
    stage_1_second_rater = {
        'case': case_ar,
        'repository': repository_ar,
        'number': number_ar,
        'package': package_ar,
        'ghsa': ghsa_ar,
        'commit_fix': blank_ar
    }
    stage_1_second_rater_true = {
        'case': case_ar,
        'repository': repository_ar,
        'number': number_ar,
        'package': package_ar,
        'ghsa': ghsa_ar,
        'commit_fix': commit_fix_ar
    }
    pd.DataFrame(stage_1_second_rater).to_csv(PATH_VULNERABILITY_FIXES['stage_1_second_rater'], index=False)
    pd.DataFrame(stage_1_second_rater_true).to_csv(PATH_VULNERABILITY_FIXES['stage_1_second_rater_true'], index=False)