import csv
import random

import docx
from docx import Document
from docx.enum.dml import MSO_THEME_COLOR_INDEX
import sys
import pandas as pd
from ast import literal_eval

sys.path.append('..')
from vulnerability_fixes.find_fixes import load_update_commits, load_advisory_database, associate_commits_with_vulns  # noqa: E402
from vulnerability_fixes.identify import identify_applicable_vulnerabilities  # noqa: E402
from finder import *  # noqa: E402


# credit: https://stackoverflow.com/a/47666747/14376026
def add_hyperlink(paragraph, text, url):
    # This gets access to the document.xml.rels file and gets a new relation id value
    part = paragraph.part
    r_id = part.relate_to(url, docx.opc.constants.RELATIONSHIP_TYPE.HYPERLINK, is_external=True)

    # Create the w:hyperlink tag and add needed values
    hyperlink = docx.oxml.shared.OxmlElement('w:hyperlink')
    hyperlink.set(docx.oxml.shared.qn('r:id'), r_id, )

    # Create a w:r element and a new w:rPr element
    new_run = docx.oxml.shared.OxmlElement('w:r')
    rPr = docx.oxml.shared.OxmlElement('w:rPr')

    # Join all the xml elements together add add the required text to the w:r element
    new_run.append(rPr)
    new_run.text = text
    hyperlink.append(new_run)

    # Create a new Run object and add the hyperlink into it
    r = paragraph.add_run ()
    r._r.append (hyperlink)

    # A workaround for the lack of a hyperlink style (doesn't go purple after using the link)
    # Delete this if using a template that has the hyperlink style in it
    r.font.color.theme_color = MSO_THEME_COLOR_INDEX.HYPERLINK
    r.font.underline = True

    return hyperlink


def create_title_page(doc):
    doc.add_heading('Labelling: Stage 2', 0)
    document.add_page_break()


def create_page(doc, index, fix_row, database):
    doc.add_heading('Case {}'.format(index), level=1)
    p = doc.add_paragraph('Project: ')
    add_hyperlink(p, fix_row['repository'], 'https://github.com/{}'.format(fix_row['repository']))
    if fix_row['associated']:
        for index_c, pr_num in enumerate(fix_row['associated']):
            p = doc.add_paragraph('', style='List Bullet')
            add_hyperlink(p, 'Pull Request {}'.format(index_c),
                          'https://github.com/{}/pull/{}'.format(fix_row['repository'], pr_num))
    else:
        p = doc.add_paragraph('Pull Request: ')
        add_hyperlink(p, fix_row['url'], fix_row['url'])
    p = doc.add_paragraph('Vulnerable Package: ')
    p.add_run(fix_row['package']).bold = True
    doc.add_paragraph('Directories')
    dirs = set()
    for file in row['files']:
        if file.split('/')[-1] in ['package.json', 'package-lock.json', 'yarn.lock', 'npm-shrinkwrap.json']:
            dirs.add(os.path.dirname(file))
    for dir in dirs:
        doc.add_paragraph(dir + '/', style='List Bullet')
    concerned_advisory_records = database[database['ghsa'] == row['ghsa']]
    table = doc.add_table(rows=1, cols=2)
    hdr_cells = table.rows[0].cells
    hdr_cells[0].text = 'Affected'
    hdr_cells[1].text = 'First Patched Release'
    for _, row_a in concerned_advisory_records.iterrows():
        row_cells = table.add_row().cells
        row_cells[0].text = str(row_a['vulnerableVersionRange'])
        row_cells[1].text = str(row_a['firstPatchedVersion'])
    if fix_row['fixed']:
        doc.add_paragraph('Fixed?: Yes')
    else:
        doc.add_paragraph('Fixed?: No')
    if not pd.isna(fix_row['commit_fix']):
        p = doc.add_paragraph('Fixing Commit: ')
        add_hyperlink(p, fix_row['commit_fix'], 'https://github.com/{}/commit/{}'.format(fix_row['repository'], str(fix_row['commit_fix'])))
        if not pd.isna(fix_row['commit_dev']):
            p = doc.add_paragraph('Fixing Commit to Dev: ')
            add_hyperlink(p, fix_row['commit_dev'],
                          'https://github.com/{}/commit/{}'.format(fix_row['repository'], str(fix_row['commit_dev'])))
        if not pd.isna(fix_row['commit_def']):
            p = doc.add_paragraph('Fixing Commit to Master: ')
            add_hyperlink(p, fix_row['commit_def'],
                          'https://github.com/{}/commit/{}'.format(fix_row['repository'], str(fix_row['commit_def'])))
        if not pd.isnull(fix_row['pr_number']):
            p = doc.add_paragraph('Fixing PR: ')
            add_hyperlink(p, str(int(fix_row['pr_number'])),
                          'https://github.com/{}/pull/{}'.format(fix_row['repository'], str(int(fix_row['pr_number']))))
    case_ar.append(index)
    repository_ar.append(fix_row['repository'])
    number_ar.append(fix_row['number'])
    package_ar.append(fix_row['package'])
    ghsa_ar.append(fix_row['ghsa'])
    A_ar.append(fix_row['A'])
    by_ar.append(fix_row['by_y'])
    if fix_row['B']:
        B_ar.append(fix_row['B'][0])
    else:
        B_ar.append(None)
    if fix_row['C']:
        C_ar.append(fix_row['C'][0])
    else:
        C_ar.append(None)
    if fix_row['D']:
        D_ar.append(fix_row['D'][0])
    else:
        D_ar.append(None)
    blank_A_ar.append(None)
    blank_B_ar.append(None)
    blank_C_ar.append(None)
    blank_D_ar.append(None)
    doc.add_page_break()


if __name__ == '__main__':
    sample_size = 357
    document = Document()
    create_title_page(document)
    fixes = pd.read_csv(PATH_VULNERABILITY_FIXES['fixes'], index_col=False)
    fixes_labels = pd.read_csv(PATH_VULNERABILITY_FIXES['fixes_labels'], index_col=False)
    fixes_labels_round_2 = pd.read_csv(PATH_VULNERABILITY_FIXES['fixes_labels_round_2'], index_col=False)
    fixes_times = pd.read_csv(PATH_VULNERABILITY_FIXES['fixes_commits_times'], index_col=False)
    fixes_labels_round_2['associated'] = fixes_labels_round_2['associated'].apply(literal_eval)
    fixes_labels_round_2['B'] = fixes_labels_round_2['B'].apply(literal_eval)
    fixes_labels_round_2['C'] = fixes_labels_round_2['C'].apply(literal_eval)
    fixes_labels_round_2['D'] = fixes_labels_round_2['D'].apply(literal_eval)
    fixes['commits'] = fixes['commits'].apply(literal_eval)
    fixes_times = fixes_times.rename(columns={'oid': 'commit_fix'})
    upd_commits = associate_commits_with_vulns()
    advisory_database = load_advisory_database()
    fixes = fixes.merge(upd_commits, how='inner', on=['url', 'repository', 'state', 'number', 'package'])
    fixes = fixes.merge(fixes_labels, how='inner', on=['repository', 'number', 'package', 'ghsa'])
    fixes.drop(columns=['fixed_x', 'fixed_y', 'by'])
    fixes = fixes.merge(fixes_labels_round_2, how='inner', on=['repository', 'number', 'package', 'ghsa'])
    fixes = fixes.join(fixes_times.set_index('commit_fix'), lsuffix='', rsuffix='_other', on='commit_fix').reset_index()
    reasoned_cases = []
    non_reasoned_bot_cases = []
    non_reasoned_non_bot_cases = []
    for index, row in fixes.iterrows():
        if len(row['D']) > 0:
            reasoned_cases.append(row)
        else:
            if row['by_y'] == 'bot':
                non_reasoned_bot_cases.append(row)
            else:
                non_reasoned_non_bot_cases.append(row)
    # second_order_sample_size = sample_size - len(reasoned_cases)
    # second_order_sample_size_bot = second_order_sample_size//2
    # second_order_sample_size_non_bot = second_order_sample_size - second_order_sample_size_bot
    # random_non_reasoned_bot_cases = random.sample(non_reasoned_bot_cases, second_order_sample_size_bot)
    # random_non_reasoned_non_bot_cases = random.sample(non_reasoned_non_bot_cases, second_order_sample_size_non_bot)
    # cases = reasoned_cases
    # cases.extend(random_non_reasoned_bot_cases)
    # cases.extend(random_non_reasoned_non_bot_cases)
    # random.shuffle(cases)
    # df_cases = pd.DataFrame(columns=list(fixes.columns), data=reasoned_cases)
    # df_cases = df_cases.sort_values(['repository', 'number'], ascending=True)
    # df_cases.reset_index()
    # cases = []
    # for index, row in df_cases.iterrows():
    #     cases.append(row)
    case_ar = []
    repository_ar = []
    number_ar = []
    package_ar = []
    ghsa_ar = []
    by_ar = []
    A_ar = []
    B_ar = []
    C_ar = []
    D_ar = []
    blank_A_ar = []
    blank_B_ar = []
    blank_C_ar = []
    blank_D_ar = []
    for index, row in enumerate(reasoned_cases):
        create_page(document, index, row, advisory_database)
    document.save(PATH_VULNERABILITY_FIXES['stage_2_second_rater_doc'])
    stage_2_second_rater = {
        'case': case_ar,
        'repository': repository_ar,
        'number': number_ar,
        'package': package_ar,
        'ghsa': ghsa_ar,
        'by': by_ar,
        # 'A': blank_A_ar,
        # 'B': blank_B_ar,
        # 'C': blank_C_ar,
        'D': blank_D_ar
    }
    stage_2_second_rater_true = {
        'case': case_ar,
        'repository': repository_ar,
        'number': number_ar,
        'package': package_ar,
        'ghsa': ghsa_ar,
        'by': by_ar,
        # 'A': A_ar,
        # 'B': B_ar,
        # 'C': C_ar,
        'D': D_ar
    }
    pd.DataFrame(stage_2_second_rater).to_csv(PATH_VULNERABILITY_FIXES['stage_2_second_rater'], index=False)
    pd.DataFrame(stage_2_second_rater_true).to_csv(PATH_VULNERABILITY_FIXES['stage_2_second_rater_true'], index=False)